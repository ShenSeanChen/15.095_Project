---
title: "Find prescription variables"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)


library(caret)
library(caTools)
library(dplyr)
# install.packages("randomForest")
library(randomForest) #for bagging and random forests 
# install.packages("gbm")
library(gbm) #for boosting
library(rpart) # for building CART model
# install.packages("rpart.plot")
library(rpart.plot)
```


### Load data, factorize columns, clean, sanity check, etc
```{r}
data = read.csv("data_clustered2.csv")

k=2
data.km = kmeans(data, k)
data.km$cluster
data$km <- data.km$cluster

#factorize columns
# cols <- c("Cluster", 
#           "Answer.bed.time.normal",
#           "Answer.ethnicity",
#           "Answer.bed.time.yesterday",
#           "Answer.gender",
#           "Answer.income",
#           "Answer.introvert",
#           "Answer.location",
#           "Answer.marital",
#           "Answer.occupation",
#           "Answer.prefer.activity",
#           "Answer.rise.time.normal",
#           "Answer.rise.time.yesterday",
#           "Answer.social.event.yesterday",
#           "Answer.sports")
cols <- c("Cluster")
data[cols] <- lapply(data[cols], factor)
```

### Split data according to clusters (3)
```{r}
cluster1 <-
  data %>%
  filter(Cluster == 0)

cluster2 <-
  data %>%
  filter(Cluster == 1)

# cluster4 <-
#   data %>%
#   filter(Cluster == 3)

# cluster5 <-
#   data %>%
#   filter(Cluster == 4)
```


### For each cluster, split data into test train
```{r}
require(caTools)  # loading caTools library

# #Cluster 1
# sample = sample.split(cluster1,SplitRatio = 0.75)
# train1 =subset(cluster1,sample ==TRUE)
# test1=subset(cluster1, sample==FALSE)
#      
# #Cluster 2
# sample = sample.split(cluster2,SplitRatio = 0.75)
# train2 = subset(cluster2,sample ==TRUE)
# test2 = subset(cluster2, sample==FALSE)


#Cluster 1
sample = sample.split(cluster1,SplitRatio = 0.75)
train1 =subset(cluster1,sample ==TRUE)%>% select(-Cluster) %>% select(-Answer.easy.concentration) %>% select(-Answer.easy.conversation) %>% select(- Answer.energetic ) %>% select(-Answer.tired ) %>% select(-Answer.sleepy)
test1=subset(cluster1, sample==FALSE)%>% select(-Cluster) %>% select(-Answer.easy.concentration) %>% select(-Answer.easy.conversation) %>% select(- Answer.energetic ) %>% select(-Answer.tired ) %>% select(-Answer.sleepy)
     
#Cluster 2
sample = sample.split(cluster2,SplitRatio = 0.75)
train2 = subset(cluster2,sample ==TRUE)%>% select(-Cluster) %>% select(-Answer.easy.concentration) %>% select(-Answer.easy.conversation) %>% select(- Answer.energetic ) %>% select(-Answer.tired ) %>% select(-Answer.sleepy)
test2 = subset(cluster2, sample==FALSE)%>% select(-Cluster) %>% select(-Answer.easy.concentration) %>% select(-Answer.easy.conversation) %>% select(- Answer.energetic ) %>% select(-Answer.tired ) %>% select(-Answer.sleepy)



```



### Modeling

```{r}
library(readr)
library(lubridate)
library(magrittr)
```


### 1. CART
```{r}
#Cluster 1
cps <- data.frame(.cp = c(.00001,0.0001,0.001,0.01,0.1))
set.seed(123)

cpCV = train(Energy_today ~ .,
             trControl=trainControl(method="cv",number=10), 
             data=train1, method="rpart",minbucket=5,
             tuneGrid=cps, metric="Rsquared", maximize=TRUE)
cpCV
best.cp = cpCV$bestTune
best.cp

ggplot(cpCV$results, aes(x=factor(cp), y=Rsquared)) +
  geom_point() +
  theme_bw() +
  ylim(0,1) + 
  xlab("cp parameter") +
  ylab("Cross-validated R2") +
  ggtitle("10-Fold Cross Validation Result") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
treeFinal1 <- rpart(Energy_today ~ ., 
          data=train1, 
          minbucket = 5, cp=best.cp)

prp(treeFinal1, digits = 3, varlen = 0, faclen = 0)
```


```{r}
#Get variable importance
importance <- 
  treeFinal1$variable.importance
importance1.cart <- data.frame(importance)
importance1.cart
```

```{r}
#Out of sample R2
T1.test.pred = predict(treeFinal1, newdata = test1)
SST = sum((test1$Energy_today - mean(test1$Energy_today))^2)
SSE = sum((T1.test.pred - test1$Energy_today)^2)
T1.out.R2 <- 1 - SSE/SST 
T1.out.R2
```


```{r}
#Cluster 2
cps <- data.frame(.cp = c(.00001,0.0001,0.001,0.01,0.1))
set.seed(123)

cpCV = train(Energy_today ~ .,
             trControl=trainControl(method="cv",number=10), 
             data=train2, method="rpart",minbucket=5,
             tuneGrid=cps, metric="Rsquared", maximize=TRUE)
cpCV
best.cp = cpCV$bestTune
best.cp

ggplot(cpCV$results, aes(x=factor(cp), y=Rsquared)) +
  geom_point() +
  theme_bw() +
  ylim(0,1) + 
  xlab("cp parameter") +
  ylab("Cross-validated R2") +
  ggtitle("10-Fold Cross Validation Result") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
treeFinal2 <- rpart(Energy_today ~ ., 
          data=train2, 
          minbucket = 5, cp=best.cp)

prp(treeFinal2, digits = 3, varlen = 0, faclen = 0)
```


```{r}
#Get variable importance
importance <- 
  treeFinal2$variable.importance
importance2.cart <- data.frame(importance)
importance2.cart
```

```{r}
#Out of sample R2
T2.test.pred = predict(treeFinal2, newdata = test2)
SST = sum((test2$Energy_today - mean(test2$Energy_today))^2)
SSE = sum((T2.test.pred - test2$Energy_today)^2)
T2.out.R2 <- 1 - SSE/SST 
T2.out.R2
```














### 2. RF
```{r}
#Cluster 1
rf.oob <- 
  train(x = train1 %>% select(-Energy_today),
                      y = train1$Energy_today,
                      method="rf",
                      tuneGrid=data.frame(mtry=1: 11),
                      ntree=80, nodesize=25,
                      trControl=trainControl(method="oob"))

best.mtry <- rf.oob$bestTune[[1]]
best.mtry

rf.final1 = randomForest(Energy_today ~ .,
          data=train1, 
                        mtry=rf.oob$bestTune[[1]],
                        ntree=80, nodesize=25)

importance <- 
  rf.final1$importance[order(-rf.final1$importance),]
importance1.rf <- data.frame(importance)
importance1.rf
```

```{r}
ggplot(rf.oob$results, aes(x=mtry, y=Rsquared)) +
  geom_point(size=1) +
  theme_bw() +
  xlab("Number of variables per split") +
  ylab("Out-of-bag R^2") +
  ggtitle("Out of Bag Result for Different mtry Parameters") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
rf.test.pred1 = predict(rf.final1, newdata = test1)
SST = sum((test1$Energy_today - mean(test1$Energy_today))^2)
SSE = sum((rf.test.pred1 - test1$Energy_today)^2)
rf1.out.R2 <- 1 - SSE/SST
rf1.out.R2
```



```{r}
#Cluster 2
rf.oob <- 
  train(x = train2 %>% select(-Energy_today),
                      y = train2$Energy_today,
                      method="rf",
                      tuneGrid=data.frame(mtry=1: 11),
                      ntree=80, nodesize=25,
                      trControl=trainControl(method="oob"))

best.mtry <- rf.oob$bestTune[[1]]
best.mtry

rf.final2 = randomForest(Energy_today ~ .,
          data=train1, 
                        mtry=rf.oob$bestTune[[1]],
                        ntree=80, nodesize=25)

importance <- 
  rf.final2$importance[order(-rf.final2$importance),]
importance2.rf <- data.frame(importance)
importance2.rf
```

```{r}
ggplot(rf.oob$results, aes(x=mtry, y=Rsquared)) +
  geom_point(size=1) +
  theme_bw() +
  xlab("Number of variables per split") +
  ylab("Out-of-bag R^2") +
  ggtitle("Out of Bag Result for Different mtry Parameters") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
rf.test.pred2 = predict(rf.final2, newdata = test2)
SST = sum((test2$Energy_today - mean(test2$Energy_today))^2)
SSE = sum((rf.test.pred2 - test2$Energy_today)^2)
rf2.out.R2 <- 1 - SSE/SST
rf2.out.R2
```


```{r}
importance1.rf
importance1.cart

importance2.rf
importance2.cart


```









 ## 3. Linear Regression? (DISCARDED -- Shitty result :( )
```{r}
#Cluster 1
c1_lm_fit <- 
  lm(formula = Energy_today ~ ., 
          data = train1)
summary(c1_lm_fit)
```

```{r}
c1_lm_predict <- predict(c1_lm_fit, test1)
SSE = sum((test1$Energy_today - c1_lm_predict)^2)
SST = sum((test1$Energy_today - mean(test1$Energy_today))^2)
OSR2 = 1 - SSE/SST
OSR2
```


```{r}
#Cluster 2
c2_lm_fit <- 
  lm(formula = Energy_today ~ ., 
          data = train2)
summary(c2_lm_fit)
```

```{r}
c2_lm_predict <- predict(c2_lm_fit, test2)
SSE = sum((test2$Energy_today - c2_lm_predict)^2)
SST = sum((test2$Energy_today - mean(test2$Energy_today))^2)
OSR2 = 1 - SSE/SST
OSR2
```

### Ridge & Lasso Regressions
```{r}
##### Ridge regression and Lasso
train1 <- train1

# %>% select(-Cluster) %>% select(-Answer.easy.concentration) %>% select(-Answer.easy.conversation) %>% select(- Answer.energetic ) %>% select(-Answer.tired ) %>% select(-Answer.sleepy)

test1 <- test1

# %>% select(-Cluster) %>% select(-Answer.easy.concentration) %>% select(-Answer.easy.conversation) %>% select(- Answer.energetic ) %>% select(-Answer.tired ) %>% select(-Answer.sleepy)

# The built-in functions for ridge regression and Lasso make use of train and test matrices, defined as follows:
x.train=model.matrix(Energy_today~.-1,data=train1) # The "-1" just mean that we are excluding the constant term (that is, the intercept)
y.train=train1$Energy_today# Here, we are only including the dependent variable.
x.test=model.matrix(Energy_today~.-1,data=test1) 
y.test=test1$Energy_today

# Let us look at what the model matrix looks like:
x.train
# When there is a categorical variable, the model matrix will include dummy variables with 0/1 values

lambdas.ridge <- exp(seq(10, -5, -.01))
lambdas.lasso <- exp(seq(5, -5, -.01))

# Both ridge regression and lasso use the same function" glmnet()
# The first two arguments are the "x" variables and the "y" variable
# The next argument is the "alpha" parameter---equal to 0 for ridge and 1 for lasso (the default value is 1)
# The last argument is the set of lambda values to try
library(glmnet)
ridge=glmnet(x.train,y.train,alpha=0,lambda=lambdas.ridge)
lasso=glmnet(x.train,y.train,alpha=1,lambda=lambdas.lasso)

# We can now plot the ridge path and the lasso path
# The bottom x axis reports the value of log(lambda)
# The values (y axis) correspond to the regression coefficients
# The top x axis reports the corresponding number of non-zero coefficients
plot(ridge,"lambda")
plot(lasso,"lambda")
# Note that both methods shrink the coefficients: The larger the lambda, the smaller the coefficients
# The main difference is that lasso brings the coefficients all the way to 0 but ridge regression does not

# The next question is: What is the best value of lambda?
# We could make directly test-set predictions and choose the best one
# But that would be cheating: You need to set the value of lambda without looking at the test set!
# Therefore, we turn to cross-validation, using the cv.glmnet() function

# Again, let us set the seed so we can all get the same results
set.seed(144)

# Here is the cross-validation syntax
cv.ridge <- cv.glmnet(x.train,y.train,alpha=0,lambda=lambdas.ridge,nfolds=10)
cv.lasso <- cv.glmnet(x.train,y.train,alpha=1,lambda=lambdas.ridge,nfolds=10)

# Let us explore the results
cv.ridge
cv.lasso

# Let us plot the results, that is, the cross-validation mean squared error as a function of log(lambda)
# Again, the glmnet package makes it nice and easy for us
plot(cv.lasso)
plot(cv.ridge)

# We can retrieve the best value of lambda and the 1-SE value of lambda, based on the cross-validation results
ridge.lambda.cv <- cv.ridge$lambda.min
ridge.lambda.1SE.cv <- cv.ridge$lambda.1se   # lambda.1se = lambda.min + 1*se (errs on the side of parsimony)
lasso.lambda.cv <- cv.lasso$lambda.min
lasso.lambda.1SE.cv <- cv.lasso$lambda.1se

# Armed with these values of lambda, we can now re-train the model on the full training set and evaluate its out-of-sample performance on the test set
# Do not forget to re-train your model; if you rely on cross-validation outputs, you are effectively using a subset of the training set---and you can do better than that!

ridge.final <- glmnet(x.train,y.train,alpha=0,lambda=ridge.lambda.cv)
pred.test.final <- predict(ridge.final,x.test)
OSR2.ridge.final <- 1-sum((pred.test.final-test1$Energy_today)^2)/sum((mean(train1$Energy_today)-test1$Energy_today)^2)
OSR2.ridge.final

lasso.final <- glmnet(x.train,y.train,alpha=1,lambda=lasso.lambda.cv)
pred.test.final <- predict(lasso.final,x.test)
OSR2.lasso.final <- 1-sum((pred.test.final-test1$Energy_today)^2)/sum((mean(train1$Energy_today)-test1$Energy_today)^2)
OSR2.lasso.final


print(OSR2.lasso.final)
print(OSR2.ridge.final)

print(lasso.final$beta)
print(ridge.final$beta)



```

 

